{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-12T08:23:40.859664Z",
     "start_time": "2025-05-12T08:23:38.210933Z"
    }
   },
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"johnsmith88/heart-disease-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/johnsmith88/heart-disease-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.18k/6.18k [00:00<00:00, 3.14MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\piotr\\.cache\\kagglehub\\datasets\\johnsmith88\\heart-disease-dataset\\versions\\2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T12:49:05.608648Z",
     "start_time": "2025-05-15T12:48:52.395866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score"
   ],
   "id": "c99ea87dc1662631",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T12:49:10.030734Z",
     "start_time": "2025-05-15T12:49:10.023719Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "603eaa4bf2254bdc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T12:49:12.661829Z",
     "start_time": "2025-05-15T12:49:12.590713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Wczytanie danych\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\piotr\\\\.cache\\\\kagglehub\\\\datasets\\\\johnsmith88\\\\heart-disease-dataset\\\\versions\\\\2\\\\heart.csv\")\n",
    "df = df.dropna()\n",
    "X = StandardScaler().fit_transform(df)"
   ],
   "id": "e08dd998934d3b33",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:12:56.900357Z",
     "start_time": "2025-05-15T13:12:56.886426Z"
    }
   },
   "cell_type": "code",
   "source": "print(X[:5])",
   "id": "8e7e6141a7a87efb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.26843658  0.66150409 -0.91575542 -0.37763552 -0.65933209 -0.41887792\n",
      "   0.89125488  0.82132052 -0.71228712 -0.06088839  0.99543334  1.20922066\n",
      "   1.08985168 -1.02669772]\n",
      " [-0.15815703  0.66150409 -0.91575542  0.4791073  -0.83386117  2.38733039\n",
      "  -1.00404855  0.2559679   1.40392824  1.72713707 -2.24367514 -0.73197147\n",
      "   1.08985168 -1.02669772]\n",
      " [ 1.71659547  0.66150409 -0.91575542  0.76468824 -1.39623266 -0.41887792\n",
      "   0.89125488 -1.04869198  1.40392824  1.30141672 -2.24367514 -0.73197147\n",
      "   1.08985168 -1.02669772]\n",
      " [ 0.72407944  0.66150409 -0.91575542  0.93603681 -0.83386117 -0.41887792\n",
      "   0.89125488  0.51689988 -0.71228712 -0.91232909  0.99543334  0.23862459\n",
      "   1.08985168 -1.02669772]\n",
      " [ 0.834359   -1.51170646 -0.91575542  0.36487493  0.93082177  2.38733039\n",
      "   0.89125488 -1.87497657 -0.71228712  0.70540823 -0.6241209   2.17981673\n",
      "  -0.52212231 -1.02669772]]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:13:52.713202Z",
     "start_time": "2025-05-15T13:13:52.697651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Funkcja do oceny jakości\n",
    "def evaluate_clustering(X, labels, method_name):\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        sil = silhouette_score(X, labels)\n",
    "        ch = calinski_harabasz_score(X, labels)\n",
    "        db = davies_bouldin_score(X, labels)\n",
    "        print(f\"{method_name}:\\n  Silhouette: {sil:.4f}, Calinski-Harabasz: {ch:.4f}, Davies-Bouldin: {db:.4f}\\n\")\n",
    "    else:\n",
    "        print(f\"{method_name}:\\n  Nie wykryto więcej niż jednego klastra.\\n\")"
   ],
   "id": "fd09e8736159c2cc",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# K-means Clustering Dzieli dane na k klastrów tak, aby zminimalizować sumę kwadratów odległości punktów od ich centroidów, Klastery są kuliste, o podobnym rozmiarze i gęstości.",
   "id": "3bdc5db13595ad97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:10:27.097398Z",
     "start_time": "2025-05-15T13:10:27.020375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# K-means\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "evaluate_clustering(X, kmeans.labels_, \"K-means\")\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "evaluate_clustering(X, kmeans.labels_, \"K-means\")"
   ],
   "id": "ea58339b02399def",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means:\n",
      "  Silhouette: 0.1788, Calinski-Harabasz: 222.0721, Davies-Bouldin: 2.0692\n",
      "\n",
      "K-means:\n",
      "  Silhouette: 0.1315, Calinski-Harabasz: 134.2434, Davies-Bouldin: 2.1421\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Mean Shift nie wymaga podania liczby klastrów.\n",
    "# Wykorzystuje oszacowanie jądrowe gęstości (Kernel Density Estimation) do przesuwania punktów w kierunku lokalnych maksimów gęstości i w ten sposób podporządkowaniu grupy."
   ],
   "id": "bcc325ee0d6440cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:06:38.129281Z",
     "start_time": "2025-05-15T13:06:35.089563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mean Shift\n",
    "meanshift = MeanShift().fit(X)\n",
    "evaluate_clustering(X, meanshift.labels_, \"Mean Shift\")"
   ],
   "id": "cb4bd06cd6e6bda3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Shift:\n",
      "  Silhouette: 0.2650, Calinski-Harabasz: 10.5343, Davies-Bouldin: 0.6042\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# GMM Modeluje dane jako mieszankę rozkładów normalnych (Gaussowskich), z różnymi środkami i wariancjami. \n",
    "# Zakłada rozklady normalne w klastrach"
   ],
   "id": "1b74f6f455f6737f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:06:50.172488Z",
     "start_time": "2025-05-15T13:06:50.052785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GMM\n",
    "gmm = GaussianMixture(n_components=3, random_state=0).fit(X)\n",
    "gmm_labels = gmm.predict(X)\n",
    "evaluate_clustering(X, gmm_labels, \"GMM\")"
   ],
   "id": "ccf4765d3d87ef2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM:\n",
      "  Silhouette: 0.1147, Calinski-Harabasz: 143.7090, Davies-Bouldin: 2.3768\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# DBSCAN Wybierz nieodwiedzony punkt.Sprawdź jego sąsiedztwo.Jeśli jest rdzeniowy, rozciągnij z niego klaster.Powtarzaj aż wszystkie punkty zostaną odwiedzone",
   "id": "b6886b744535fc19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:30:47.674255Z",
     "start_time": "2025-05-15T13:30:47.572905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=3, min_samples=5).fit(X)\n",
    "evaluate_clustering(X, dbscan.labels_, \"DBSCAN\")\n",
    "# trzeba duży w miarę epsilon, żeby był niezłe wyniki znaczy pewnie, że klastry są rzadkie"
   ],
   "id": "902be5a5181e3c15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN:\n",
      "  Silhouette: 0.0429, Calinski-Harabasz: 36.7969, Davies-Bouldin: 2.8966\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Buduje drzewo hierarchiczne, łącząc punkty/klastry według wybranej miary.\n",
    "# Każdy punkt to osobny klaster. Iteracyjnie łącz najbliższe klastry.Zatrzymaj się po osiągnięciu żądanej liczby klastrów lub kryterium.\n",
    "# Wrażliwy na wybór miary łączenia"
   ],
   "id": "1f5a7d348fb6cb88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:34:56.021696Z",
     "start_time": "2025-05-15T13:34:55.935932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Agglomerative Clustering\n",
    "agg = AgglomerativeClustering(n_clusters=3).fit(X)\n",
    "evaluate_clustering(X, agg.labels_, \"Agglomerative Clustering\")\n",
    "agg = AgglomerativeClustering(n_clusters=2).fit(X)\n",
    "evaluate_clustering(X, agg.labels_, \"Agglomerative Clustering\")"
   ],
   "id": "f586a8668c693964",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agglomerative Clustering:\n",
      "  Silhouette: 0.1588, Calinski-Harabasz: 139.8322, Davies-Bouldin: 2.0726\n",
      "\n",
      "Agglomerative Clustering:\n",
      "  Silhouette: 0.1742, Calinski-Harabasz: 191.3214, Davies-Bouldin: 2.1025\n",
      "\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Są dwa klastry?? dwa algorytmy mają najlepsze wynki dla dwoch klastrów \n",
    "\n",
    "### Wyniki i co z nich wynika"
   ],
   "id": "87ea65f1c064b4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:37:30.624289Z",
     "start_time": "2025-05-15T13:37:30.501340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agg = AgglomerativeClustering(n_clusters=2).fit(X)\n",
    "evaluate_clustering(X, agg.labels_, \"Agglomerative Clustering\")\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "evaluate_clustering(X, kmeans.labels_, \"K-means\")"
   ],
   "id": "16a03b586f8b82ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agglomerative Clustering:\n",
      "  Silhouette: 0.1742, Calinski-Harabasz: 191.3214, Davies-Bouldin: 2.1025\n",
      "\n",
      "K-means:\n",
      "  Silhouette: 0.1788, Calinski-Harabasz: 222.0721, Davies-Bouldin: 2.0692\n",
      "\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Natomiast tak czy siak dla pierwszej i ostatniej metryki najlepsze wyniki to meanshift",
   "id": "2ad49e52338d965c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:39:16.172588Z",
     "start_time": "2025-05-15T13:39:12.958967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "meanshift = MeanShift().fit(X)\n",
    "evaluate_clustering(X, meanshift.labels_, \"Mean Shift\")"
   ],
   "id": "a978f3b83b6ea48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Shift:\n",
      "  Silhouette: 0.2650, Calinski-Harabasz: 10.5343, Davies-Bouldin: 0.6042\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dodatkowo jasno widać z metody DBSCan, że klastry są rzadkie i jest to jasne, trudno to porównać do czegoś, ale raczej nie są mega gęste, mimo strojenia i liczby próbek i wartości epsilon, wyniki są najgorsze z wszytskich metod",
   "id": "422bfebb42687227"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:46:37.691543Z",
     "start_time": "2025-05-15T13:46:37.615483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dbscan = DBSCAN(eps=3, min_samples=5).fit(X)\n",
    "evaluate_clustering(X, dbscan.labels_, \"DBSCAN\")\n",
    "# trzeba duży w miarę epsilon, żeby był niezłe wyniki znaczy pewnie, że klastry są rzadkie"
   ],
   "id": "1fc78a0b974559be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN:\n",
      "  Silhouette: 0.0429, Calinski-Harabasz: 36.7969, Davies-Bouldin: 2.8966\n",
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:47:04.950243Z",
     "start_time": "2025-05-15T13:47:04.697057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gmm = GaussianMixture(n_components=3, random_state=0).fit(X)\n",
    "gmm_labels = gmm.predict(X)\n",
    "evaluate_clustering(X, gmm_labels, \"GMM\")"
   ],
   "id": "99b214616f763136",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM:\n",
      "  Silhouette: 0.1147, Calinski-Harabasz: 143.7090, Davies-Bouldin: 2.3768\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nie mają też raczej rozkładu normalnego, ponieważ wyniki z mieszaniny gaussa są średnie.\n",
    "\n",
    "Silhouette – czy punkty są bliżej swojego klastra niż innych\n",
    "\n",
    "Calinski-Harabasz – czy klastry są zwarte i daleko od siebie\n",
    "\n",
    "Davies-Bouldin – jak bardzo klastry na siebie nachodzą (im mniej, tym lepiej)"
   ],
   "id": "a92f99383e711b33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Czyli mean_shift wygrywa jeśli chodzi o sensowny podział danych, a agglomerative clustering i k-means jesli chodzi o fajny podział statystycznie, co jest ciekawe bo to oznacza, że ładne grupy są dwie, ale da się podzielić bardziej nieregularnie dane lub np.poprostu bardziej specyficznym jądrem gęstości, które dadzą najlepsze wyniki.",
   "id": "13e47cc4c3988ea6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
